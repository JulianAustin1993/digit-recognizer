{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covolutional Neural Network\n",
    "\n",
    "We will explore Covnet structure in this notebook. Using tensorboard as a means to log metrics for training and valiidation.\n",
    "\n",
    "784 - **[32C5-32C5S2-64C5-64C5S2]** - 128 - 10: is the structure which is best from this exploration with drop out and batch normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/b7064522/opt/miniconda3/envs/drenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(\"../\")\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(\"Setting up logging...\")\n",
    "\n",
    "\n",
    "from src.utils import CustomMnistDataset, imshow, train_covnet\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "DATA_DIR= os.getenv('DATA_DIR')\n",
    "SEED = int(os.getenv('SEED')) #type: ignore\n",
    "TENSORBOARD_DIR = Path(os.getenv('TENSORBOARD_DIR')) #type: ignore\n",
    "MODEL_DIR = Path(os.getenv('MODEL_DIR')) #type: ignore\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = nn.Sequential(\n",
    "    T.RandomAffine(degrees = 10, translate = (0.1, 0.1), scale = (0.9, 1.1))\n",
    ")\n",
    "train_dataset = CustomMnistDataset(img_dir = DATA_DIR, type='train', transform=augmentor)\n",
    "val_dataset = CustomMnistDataset(img_dir = DATA_DIR, type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "SHUFFLE = True\n",
    "EPOCHS = 50\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = SHUFFLE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = SHUFFLE)\n",
    "optimizer_wrapper = lambda x: optim.SGD(x, lr=0.01, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 784 - **[32C5-P2S2]** - 128 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name='32C5-P2S2-128-10'\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # (32, 24, 24)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # (32, 12, 12)\n",
    "        self.fc1 = nn.Linear(32 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "train_dict = train_covnet(\n",
    "    net = Net(),\n",
    "    dataloader = train_dataloader,\n",
    "    epochs = EPOCHS,\n",
    "    optimizer_wrapper = optimizer_wrapper,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    writer = SummaryWriter(Path(TENSORBOARD_DIR, exp_name)), #type; ignore\n",
    "    val_dataloader = val_dataloader\n",
    ")\n",
    "torch.save(train_dict.get('model').state_dict(), Path(MODEL_DIR, exp_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_dataloader))\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(Path(MODEL_DIR, exp_name)))\n",
    "model.eval()\n",
    "inputs = inputs[:10]\n",
    "classes = classes[:10]\n",
    "outputs = model(inputs) #type: ignore\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "out = make_grid(inputs, nrow=5)\n",
    "title = 'Predicted: '+' '.join(f'{j}' for j in predicted)+'\\nActual:      '+\\\n",
    "    ' '.join((f'{j}' for j in classes))\n",
    "imshow(out, title = title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 784 - **[32C5-P2S2-64C5-P2S2]** - 128 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name='32C5-P2S2-64C5-P2S2-128-10'\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (32, 12, 12)\n",
    "        x = self.pool((F.relu(self.conv2(x)))) #(64, 4, 4)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "train_dict = train_covnet(\n",
    "    net = Net(),\n",
    "    dataloader = train_dataloader,\n",
    "    epochs = EPOCHS,\n",
    "    optimizer_wrapper = optimizer_wrapper,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    writer = SummaryWriter(Path(TENSORBOARD_DIR, exp_name)), #type; ignore\n",
    "    val_dataloader = val_dataloader\n",
    ")\n",
    "torch.save(train_dict.get('model').state_dict(), Path(MODEL_DIR, exp_name) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_dataloader))\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(Path(MODEL_DIR, exp_name)))\n",
    "model.eval()\n",
    "inputs = inputs[:10]\n",
    "classes = classes[:10]\n",
    "outputs = model(inputs) #type: ignore\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "out = make_grid(inputs, nrow=5)\n",
    "title = 'Predicted: '+' '.join(f'{j}' for j in predicted)+'\\nActual:      '+\\\n",
    "    ' '.join((f'{j}' for j in classes))\n",
    "imshow(out, title = title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 784 - **[32C5-P2S2-64C5-P2S2]** - 128 - 10 with Batch normaliization and Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name='32C5-P2S2-64C5-P2S2-128-10-BN-DO'\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.pool(F.relu(self.bn1(self.conv1(x))))) # (32, 12, 12)\n",
    "        x = self.dropout(self.pool(F.relu(self.bn2((self.conv2(x))))))#(64, 4, 4)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.dropout(F.relu(self.bn3(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "train_dict = train_covnet(\n",
    "    net = Net(),\n",
    "    dataloader = train_dataloader,\n",
    "    epochs = EPOCHS,\n",
    "    optimizer_wrapper = optimizer_wrapper,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    writer = SummaryWriter(Path(TENSORBOARD_DIR, exp_name)), #type; ignore\n",
    "    val_dataloader = val_dataloader\n",
    ")\n",
    "torch.save(train_dict.get('model').state_dict(), Path(MODEL_DIR, exp_name) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_dataloader))\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(Path(MODEL_DIR, exp_name)))\n",
    "model.eval()\n",
    "outputs = model(inputs) #type: ignore\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "out = make_grid(inputs, nrow=5)\n",
    "title = 'Predicted: '+' '.join(f'{j}' for j in predicted)+'\\nActual:      '+\\\n",
    "    ' '.join((f'{j}' for j in classes))\n",
    "imshow(out, title = title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 784 - **[32C5-32C5S2-64C5-64C5S2]** - 128 - 10 with Batch normalization and Dropout. \n",
    "\n",
    "This mimics the Max pooling layer using a trainable convlutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name='32C5-32C5S2-64C5-64C5S2-128-10'\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # 32, 24, 24, \n",
    "        self.pool1 = nn.Conv2d(32, 32, 5, 2, padding=2) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) \n",
    "        self.pool2 = nn.Conv2d(64, 64, 5, 2, padding=2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.pool1(F.relu(self.bn1(self.conv1(x))))) # (32, 12, 12)\n",
    "        x = self.dropout(self.pool2(F.relu(self.bn2((self.conv2(x)))))) #(64, 4, 4)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.dropout(F.relu(self.bn3(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "  \n",
    "train_dict = train_covnet(\n",
    "    net = Net(),\n",
    "    dataloader = train_dataloader,\n",
    "    epochs = EPOCHS,\n",
    "    optimizer_wrapper = optimizer_wrapper,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    writer = SummaryWriter(Path(TENSORBOARD_DIR, exp_name)), #type; ignore\n",
    "    val_dataloader = val_dataloader\n",
    ")\n",
    "torch.save(train_dict.get('model').state_dict(), Path(MODEL_DIR, exp_name) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_dataloader))\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(Path(MODEL_DIR, exp_name)))\n",
    "model.eval()\n",
    "inputs = inputs[:10]\n",
    "classes = classes[:10]\n",
    "outputs = model(inputs) #type: ignore\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "out = make_grid(inputs, nrow=5)\n",
    "title = 'Predicted: '+' '.join(f'{j}' for j in predicted)+'\\nActual:      '+\\\n",
    "    ' '.join((f'{j}' for j in classes))\n",
    "imshow(out, title = title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13838a53fc594ffa30a34b5031f03b2aa916b9b3ee5245d7f75d470d94945eb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
